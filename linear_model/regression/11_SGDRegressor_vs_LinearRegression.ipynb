{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3c6be4",
   "metadata": {},
   "source": [
    "# Comparison of computation times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee0736",
   "metadata": {},
   "source": [
    "We will compare the training times and performances of LinearRegression and SGDRegressor when the number of features increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bffd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ca0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compare models\n",
    "def compare_models(n_samples, n_features):\n",
    "    print(f\"\\n--- Dataset: {n_samples} samples, {n_features} features ---\")\n",
    "\n",
    "    # Generate synthetic data\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=0.1, random_state=42)\n",
    "\n",
    "    # Linear Regression\n",
    "    start = time.time()\n",
    "    linreg = LinearRegression().fit(X, y)\n",
    "    linreg_time = time.time() - start\n",
    "    linreg_r2 = r2_score(y, linreg.predict(X))\n",
    "\n",
    "    # SGD Regressor\n",
    "    start = time.time()\n",
    "    sgd = SGDRegressor(max_iter=1000, tol=1e-3, random_state=42).fit(X, y)\n",
    "    sgd_time = time.time() - start\n",
    "    sgd_r2 = r2_score(y, sgd.predict(X))\n",
    "\n",
    "    # Display results\n",
    "    print(f\"LinearRegression - Training time: {linreg_time:.4f}s | R²: {linreg_r2:.4f}\")\n",
    "    print(f\"SGDRegressor     - Training time: {sgd_time:.4f}s | R²: {sgd_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9a2595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset: 10000 samples, 10 features ---\n",
      "LinearRegression - Training time: 0.0265s | R²: 1.0000\n",
      "SGDRegressor     - Training time: 0.0319s | R²: 1.0000\n",
      "\n",
      "--- Dataset: 10000 samples, 100 features ---\n",
      "LinearRegression - Training time: 0.8863s | R²: 1.0000\n",
      "SGDRegressor     - Training time: 0.0628s | R²: 1.0000\n",
      "\n",
      "--- Dataset: 10000 samples, 1000 features ---\n",
      "LinearRegression - Training time: 15.8792s | R²: 1.0000\n",
      "SGDRegressor     - Training time: 0.3645s | R²: 1.0000\n",
      "\n",
      "--- Dataset: 1000000 samples, 100 features ---\n",
      "LinearRegression - Training time: 9.6525s | R²: 1.0000\n",
      "SGDRegressor     - Training time: 6.9456s | R²: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run comparisons\n",
    "compare_models(10_000, 10)\n",
    "compare_models(10_000, 100)\n",
    "compare_models(10_000, 1_000)\n",
    "compare_models(1_000_000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08a6fe",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **LinearRegression** performs best on **small or low-dimensional datasets**, thanks to its direct analytical solution.  \n",
    "- **SGDRegressor** scales much better as the **number of features or samples increases**, showing significant speed advantages in **high-dimensional or large-scale data**.  \n",
    "- **Performance (R²)** remains identical because both methods converge to similar optimal coefficients under ideal conditions.  \n",
    "- The **computational cost** of LinearRegression grows roughly with **O(n²·p)**, while **SGDRegressor** grows more linearly with the number of samples and features, depending on the number of iterations.  \n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "For **small datasets**, *LinearRegression* is **simple, fast, and exact**.  \n",
    "For **large-scale or high-dimensional datasets**, *SGDRegressor* is **much more efficient** and **memory-friendly**, making it the better choice in real-world machine learning pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linear-model-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
